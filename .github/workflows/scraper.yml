name: Run JUCO Recruiting Class Scraper (Multi-Year)

on:
  workflow_dispatch:
    inputs:
      years_to_scrape:
        description: 'Which years to scrape'
        required: true
        type: choice
        options:
          - 'All Years (2016-2027)'
          - 'Historical (2016-2019)'
          - 'Core Years (2020-2022)'
          - 'Recent Years (2023-2027)'
          - '2016 Only'
          - '2017 Only'
          - '2018 Only'
          - '2019 Only'
          - '2020 Only'
          - '2021 Only'
          - '2022 Only'
          - '2023 Only'
          - '2024 Only'
          - '2025 Only'
          - '2026 Only'
          - '2027 Only'
        default: 'All Years (2016-2027)'
      test_mode:
        description: 'Test mode (50 players) or Full scrape'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  # Job 1: Determine which years to run
  setup:
    runs-on: ubuntu-latest
    outputs:
      years: ${{ steps.set-years.outputs.years }}
    steps:
      - id: set-years
        run: |
          case "${{ github.event.inputs.years_to_scrape }}" in
            "All Years (2016-2027)")
              echo 'years=["2016","2017","2018","2019","2020","2021","2022","2023","2024","2025","2026","2027"]' >> $GITHUB_OUTPUT
              ;;
            "Historical (2016-2019)")
              echo 'years=["2016","2017","2018","2019"]' >> $GITHUB_OUTPUT
              ;;
            "Core Years (2020-2022)")
              echo 'years=["2020","2021","2022"]' >> $GITHUB_OUTPUT
              ;;
            "Recent Years (2023-2027)")
              echo 'years=["2023","2024","2025","2026","2027"]' >> $GITHUB_OUTPUT
              ;;
            "2016 Only")
              echo 'years=["2016"]' >> $GITHUB_OUTPUT
              ;;
            "2017 Only")
              echo 'years=["2017"]' >> $GITHUB_OUTPUT
              ;;
            "2018 Only")
              echo 'years=["2018"]' >> $GITHUB_OUTPUT
              ;;
            "2019 Only")
              echo 'years=["2019"]' >> $GITHUB_OUTPUT
              ;;
            "2020 Only")
              echo 'years=["2020"]' >> $GITHUB_OUTPUT
              ;;
            "2021 Only")
              echo 'years=["2021"]' >> $GITHUB_OUTPUT
              ;;
            "2022 Only")
              echo 'years=["2022"]' >> $GITHUB_OUTPUT
              ;;
            "2023 Only")
              echo 'years=["2023"]' >> $GITHUB_OUTPUT
              ;;
            "2024 Only")
              echo 'years=["2024"]' >> $GITHUB_OUTPUT
              ;;
            "2025 Only")
              echo 'years=["2025"]' >> $GITHUB_OUTPUT
              ;;
            "2026 Only")
              echo 'years=["2026"]' >> $GITHUB_OUTPUT
              ;;
            "2027 Only")
              echo 'years=["2027"]' >> $GITHUB_OUTPUT
              ;;
          esac

  # Job 2: Scrape selected years in parallel
  scrape:
    needs: setup
    strategy:
      matrix:
        year: ${{ fromJson(needs.setup.outputs.years) }}
      fail-fast: false
    
    runs-on: ubuntu-latest
    timeout-minutes: 360
    
    name: Scrape JUCO ${{ matrix.year }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        playwright install chromium
    
    - name: Run scraper for ${{ matrix.year }}
      run: python scraper.py
      env:
        TEST_MODE: ${{ github.event.inputs.test_mode }}
        SCRAPE_YEAR: ${{ matrix.year }}
    
    - name: Validate output structure
      run: python validate_output.py
      if: always()
    
    - name: Upload CSV for combination
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: csv_for_combine_${{ matrix.year }}
        path: output/*.csv
        retention-days: 7
    
    - name: Upload individual CSV output for ${{ matrix.year }}
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: JUCO_CSV_Output_${{ matrix.year }}
        path: output/*.csv
        retention-days: 90
    
    - name: Upload diagnostics for ${{ matrix.year }}
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: JUCO_Diagnostics_${{ matrix.year }}
        path: output/diagnostics/
        retention-days: 30

  # Job 3: Combine all CSVs into one
  combine:
    needs: scrape
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Download all CSV artifacts
      uses: actions/download-artifact@v4
      with:
        pattern: csv_for_combine_*
        path: downloaded_csvs
        merge-multiple: true
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install pandas
      run: pip install pandas
    
    - name: Combine CSVs
      run: |
        python3 << 'EOF'
        import pandas as pd
        import glob
        import os
        from datetime import datetime
        
        csv_files = glob.glob('downloaded_csvs/*.csv')
        
        if not csv_files:
            print("‚ö†Ô∏è  No CSV files found to combine")
            exit(0)
        
        print(f"üìä Found {len(csv_files)} CSV files to combine")
        
        dfs = []
        for file in sorted(csv_files):
            print(f"  ‚Üí Reading {os.path.basename(file)}")
            df = pd.read_csv(file)
            dfs.append(df)
        
        combined_df = pd.concat(dfs, ignore_index=True)
        
        # Sort by Recruiting Year (desc) then Composite JUCO National Rank (asc)
        combined_df['Recruiting Year'] = pd.to_numeric(combined_df['Recruiting Year'], errors='coerce')
        combined_df['Composite JUCO National Rank'] = pd.to_numeric(combined_df['Composite JUCO National Rank'], errors='coerce')
        combined_df = combined_df.sort_values(
            by=['Recruiting Year', 'Composite JUCO National Rank'],
            ascending=[False, True]
        )
        
        years = sorted(combined_df['Recruiting Year'].dropna().unique().astype(int))
        year_range = f"{min(years)}-{max(years)}" if len(years) > 1 else str(years[0])
        timestamp = datetime.now().strftime('%Y%m%d')
        
        output_file = f'juco_recruiting_class_{year_range}_combined_{timestamp}.csv'
        combined_df.to_csv(output_file, index=False)
        
        print(f"\n‚úÖ Combined CSV created: {output_file}")
        print(f"üìä Total players: {len(combined_df):,}")
        print(f"üìÖ Years covered: {year_range}")
        print(f"üìè File size: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB")
        EOF
    
    - name: Upload combined CSV
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: JUCO_Combined_CSV_All_Years
        path: juco_recruiting_class_*_combined_*.csv
        retention-days: 90
    
    - name: Display summary
      if: always()
      run: |
        echo "=========================================="
        echo "üéâ JUCO SCRAPING COMPLETE!"
        echo "=========================================="
        echo ""
        echo "üì¶ Artifacts created:"
        echo "  ‚Ä¢ JUCO_Combined_CSV_All_Years (single file with all years)"
        echo "  ‚Ä¢ JUCO_CSV_Output_YEAR (individual files per year)"
        echo "  ‚Ä¢ JUCO_Diagnostics_YEAR (debug info per year)"
        echo ""
        echo "Download from the 'Artifacts' section above!"
        echo "=========================================="
